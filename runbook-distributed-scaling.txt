1)  Prerequisites-
    Install python3.7 
        sudo yum install python3 -y
    Install aws cli - v1
        pip3 install --upgrade --user awscli (install using pip3)
        export PATH=$HOME/.local/bin:$PATH (add cli to path)
        source ~/.bash_profile (reload current session)
        aws --version (verify)
    Install kops
        download executable - curl -LO https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '"' -f 4)/kops-darwin-amd64
        add execute permissions - chmod +x kops-darwin-amd64
        add to path - sudo mv kops-darwin-amd64 /usr/local/bin/kops
        verify - kops version
    Install kubectl
        download executable - curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl
        add execute permissions - chmod +x ./kubectl
        add to path - sudo mv ./kubectl /usr/local/bin/kubectl
        verify - kubectl version --client
    Install helm
        download executable - curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3
        add execute permissions - chmod 700 get_helm.sh
        execute - ./get_helm.sh

2)  Set Kops env var in $HOME/.bash_profile 
    KOPS_STATE_STORE=s3://bucket/url
    NAME=some.dns.ready.cluster.name (digions.org.in)

3)  Create Route 53 Record Set, same as cluster-name set in NAME
    Add NS entries to parent dns provider(godaddy-optional)

4)  Create cluster
    kops create cluster --name=$NAME --state=$KOPS_STATE_STORE --zones=us-west-2a,us-west-2b --cloud-labels "Resource=KOPS,NAME=KOPS-ADMIN,Owner=Ankit"
    #create cluster dds will give

5)  Create instance group 
    kops create ig ig-name --name=$NAME(in both worker igs add nodeLables type: someUniqueValueAcrossIgs under spec.nodeLabels.type: compute/amd-compute)
    kops update cluster $NAME --yes

6)  Set kubectl context
    kops export kubecfg $NAME
    #how jp did for our read only access. 
    #how they exporeted the conf.

7)  Clone Repo 
    git clone https://github.com/kazekin94/digions.org.in.git

8)  Install application using helm (Assumes repo was cloned in home) #This will act as one type of application in customer env
    NOTE-This step will install application on nodes with label type: compute
    helm install --generate-name digions.org.in/dummy/

9)  Verify app object installation
    kubectl get all (should give 1 dummy srv, 2 dummy deployment, 2 dummy replicaset, 4 dummy pods, 1 configmap)

10)  Verify application versions
     curl lb-dns-name (running cmd multiple time should result in nginx and apache default pages)

11) Add SQS permissions to master and slave nodes #this will act as another type of application in customer env
    aws iam attach-role-policy --role-name nodes/masters.digions.org.in --policy-arn arn:aws:iam::aws:policy/AmazonSQSFullAccess
    aws iam attach-role-policy --role-name nodes/masters.digions.org.in --policy-arn arn:aws:iam::aws:policy/CloudWatchFullAccess
    #narrow down exact permission sqs, cw
    #only those permission for each node group which requires it

12) Install aws cw hpa in a new custom-metrics namespace, namespace is created automatically
    kubectl apply -f https://raw.githubusercontent.com/awslabs/k8s-cloudwatch-adapter/master/deploy/adapter.yaml
    #exposing kube-metrics-server --> metrics to cloudwatch

13) Verify installation 
    kubectl get --raw "/apis/external.metrics.k8s.io/v1beta1" | jq
    Output should be 
    {
        "kind": "APIResourceList",
        "apiVersion": "v1",
        "groupVersion": "external.metrics.k8s.io/v1beta1",
        "resources": [
        ]
    }    

14) Clone AWS sample app in home dir
    git clone https://github.com/awslabs/k8s-cloudwatch-adapter.git

15) Add nodes affinity labels on both producer and consumer
    cd ~/k8s-cloudwatch-adapter/samples/sqs/deploy/
    vim consumer-deployment.yaml
    #under spec.template.spec add 
    affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                - key: type
                  operator: In
                  values:
                  - amd-compute
    save and quit
    vim producer-deployment.yaml
    #under spec.template.spec add 
    affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                - key: type
                  operator: In
                  values:
                  - amd-compute
    save and quit

17) Add policy to IAM role nodes.digions.org.in
    {
        "Version": "2012-10-17",
        "Statement": [
                {
                    "Effect": "Allow",
                    "Action": [
                        "autoscaling:DescribeAutoScalingGroups",
                        "autoscaling:DescribeAutoScalingInstances",
                        "autoscaling:DescribeLaunchConfigurations",
                        "autoscaling:SetDesiredCapacity",
                        "autoscaling:TerminateInstanceInAutoScalingGroup"
                    ],
                    "Resource": "*"
                }
        ]
    }
    #min x, max 2x, can it go too 3x asg

18) Copy cluster autoscaler default yaml to a new file in home dir
    https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/cloudprovider/aws/examples/cluster-autoscaler-multi-asg.yaml

19) Under command tab add correct instance group name and default scaling setup while creation
    command:
    - ./cluster-autoscaler
    - --v=4
    - --stderrthreshold=info
    - --cloud-provider=aws
    - --skip-nodes-with-local-storage=false
    - --expander=least-waste
    - --nodes=1:5:nodes.digions.org.in
    - --nodes=1:7:amd-nodes.digions.org.in

20) Add cert under hostPath
    hostPath:
        path: "/etc/ssl/certs/ca-bundle.crt"
        path: "/etc/ssl/certs/ca-certificates.crt"

21) Apply cluster autoscaler
    kubectl apply -f <filename>.yaml

22) Apply consumer deployment
    kubectl apply -f consumer-deployment.yaml

23) Create CRD external metrics
    kubectl apply -f externalmetric.yaml

24) Deploy hpa
    kubectl apply -f hpa.yaml 

25) Deploy producer
    kubectl apply -f producer-deployment.yaml
    #sqs q helloworld will be created, load will be preoduced in queue

26) watch scale up of pods
    kubectl get hpa sqs-consumer-scaler -w

27) Install alb-controller
    wget https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.8/docs/examples/alb-ingress-controller.yaml
    edit cluster name --> --cluster-name=clusterName
    Apply RBAC roles-->
    kubectl apply -f https://raw.githubusercontent.com/kubernetes-sigs/aws-alb-ingress-controller/v1.1.8/docs/examples/rbac-role.yaml
    kubectl apply -f digions.org.in/al-ingress-controller/alb-ingress-controller.yaml


28) Uninstall app
    helm ls (copy name)
    helm uninstall name

29) Tear down cluster
    kops delete cluster $NAME --yes
